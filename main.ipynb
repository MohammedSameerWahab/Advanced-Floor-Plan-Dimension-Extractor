{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d95077f",
   "metadata": {},
   "source": [
    "# Floorplan Dimension Extractor\n",
    "\n",
    "This notebook implements a Python pipeline to extract dimensions and appliance codes from a floorplan PDF.\n",
    "\n",
    "**The process is as follows:**\n",
    "1.  **Load PDF**: Read the specified page from the input PDF file.\n",
    "2.  **Image Conversion**: Since the PDF is image-based, convert the page into an image format that can be processed by an OCR engine.\n",
    "3.  **OCR Extraction**: Use Tesseract OCR to extract all text and their corresponding bounding boxes from the image.\n",
    "4.  **Pattern Matching**: Use Regular Expressions (Regex) to find text that matches dimension formats (e.g., `12' 6\"`, `34 1/2\"`) and cabinet codes (e.g., `DB24`).\n",
    "5.  **Data Conversion**: Convert the raw dimension strings into a standardized unit (float inches).\n",
    "6.  **Output Generation**: Store the results in a structured JSON file and create a new visualized PDF with bounding boxes drawn on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1a561a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# For Windows users, you might need to specify the path to the Tesseract executable\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a810b1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "INPUT_PDF_PATH = os.path.join('data', 'floorplan.pdf')\n",
    "OUTPUT_DIR = 'output'\n",
    "OUTPUT_JSON_PATH = os.path.join(OUTPUT_DIR, 'extracted_data.json')\n",
    "OUTPUT_VISUAL_PATH = os.path.join(OUTPUT_DIR, 'visualized_floorplan.pdf')\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3a8db1",
   "metadata": {},
   "source": [
    "## Step 1 & 2: PDF to Image Conversion and OCR\n",
    "\n",
    "First, we define a function to extract a page from the PDF and convert it into a high-resolution image (as a NumPy array) suitable for OCR. Then, we use `pytesseract` to perform OCR on this image. We use `image_to_data` to get detailed information, including the text, its coordinates (`left`, `top`, `width`, `height`), and the confidence score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "94606165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_page_to_image(pdf_path, page_number=0, dpi=300):\n",
    "    \"\"\"\n",
    "    Converts a specific page of a PDF to a NumPy array image.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    page = doc.load_page(page_number)\n",
    "    \n",
    "    # Render page to a pixmap (image)\n",
    "    pix = page.get_pixmap(dpi=dpi)\n",
    "    \n",
    "    # Convert pixmap to a NumPy array for OpenCV\n",
    "    img = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, pix.n)\n",
    "    \n",
    "    # If the image is RGBA, convert to BGR for OpenCV\n",
    "    if img.shape[2] == 4:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGBA2BGR)\n",
    "        \n",
    "    doc.close()\n",
    "    return img\n",
    "\n",
    "def extract_text_with_bboxes(image):\n",
    "    \"\"\"\n",
    "    Performs OCR on an image and returns text with bounding boxes.\n",
    "    \"\"\"\n",
    "    # Use pytesseract to get structured data\n",
    "    ocr_data = pytesseract.image_to_data(image, output_type=pytesseract.Output.DICT)\n",
    "    return ocr_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7f02e5",
   "metadata": {},
   "source": [
    "## Step 3, 4 & 5: Parsing and Converting Data\n",
    "\n",
    "This is the core logic. We define functions to:\n",
    "1.  **Parse Fractions**: Convert string fractions like \"1/2\" to floats.\n",
    "2.  [cite_start]**Parse Dimensions**: A powerful function that uses regex to find and convert various dimension formats (`X' Y\"`, `X' Y/Z\"`, `X\"`, etc.) into inches[cite: 5, 6].\n",
    "3.  [cite_start]**Find Patterns**: A main processing function that iterates through the OCR data, groups words that are close together, and applies regex to identify and process dimensions and codes[cite: 7]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "20066bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fraction(fraction_str):\n",
    "    \"\"\"Converts a fraction string like '1/2' to a float.\"\"\"\n",
    "    if '/' in fraction_str:\n",
    "        num, den = fraction_str.split('/')\n",
    "        return float(num) / float(den)\n",
    "    return float(fraction_str)\n",
    "\n",
    "def convert_to_inches(raw_string):\n",
    "    \"\"\"\n",
    "    Converts a single recognized dimension string (e.g., \"12' 6 1/2\\\"\") to float inches.\n",
    "    This version is more robust.\n",
    "    \"\"\"\n",
    "    total_inches = 0\n",
    "    \n",
    "    # Comprehensive regex: captures feet, and then inches which can be a whole number, a fraction, or both.\n",
    "    # Example matches: 5', 6\", 1/2\", 6 1/2\", 5' 6\", 5' 1/2\", 5' 6 1/2\"\n",
    "    pattern = re.compile(r\"(?:(\\d+)')?\\s*(?:(\\d+))?\\s*(?:(\\d+/\\d+))?\\\"?\")\n",
    "    match = pattern.search(raw_string)\n",
    "\n",
    "    if not match:\n",
    "        return 0.0\n",
    "\n",
    "    feet = match.group(1)\n",
    "    whole_inches = match.group(2)\n",
    "    fraction = match.group(3)\n",
    "\n",
    "    if feet:\n",
    "        total_inches += float(feet) * 12\n",
    "    if whole_inches:\n",
    "        total_inches += float(whole_inches)\n",
    "    if fraction:\n",
    "        num, den = fraction.split('/')\n",
    "        total_inches += float(num) / float(den)\n",
    "        \n",
    "    return total_inches\n",
    "\n",
    "def find_and_process_patterns(ocr_data):\n",
    "    \"\"\"\n",
    "    Finds and processes BOTH dimension strings AND codes from the same OCR data.\n",
    "    \"\"\"\n",
    "    dimensions = []\n",
    "    codes = []\n",
    "    \n",
    "    # Regex for codes\n",
    "    code_pattern = re.compile(r'^\\d{4}[A-Z]{2}$')\n",
    "    \n",
    "    n_boxes = len(ocr_data['text'])\n",
    "    for i in range(n_boxes):\n",
    "        # Only process words with a decent confidence score\n",
    "        if int(ocr_data['conf'][i]) > 40:\n",
    "            text = ocr_data['text'][i]\n",
    "            \n",
    "            # --- Check for Codes ---\n",
    "            if code_pattern.match(text):\n",
    "                codes.append(text)\n",
    "                continue # Move to the next word once a code is found\n",
    "\n",
    "            # --- Check for Dimensions ---\n",
    "            # This logic is simplified to look for the foot marker, which is a strong indicator\n",
    "            if \"'\" in text:\n",
    "                raw_text = text\n",
    "                # Simple logic to combine with the next word if it looks like inches\n",
    "                if i + 1 < n_boxes and '\"' in ocr_data['text'][i+1]:\n",
    "                    raw_text += \" \" + ocr_data['text'][i+1]\n",
    "\n",
    "                # Process single or combined dimensions (e.g., 12'0\" X 11'6\")\n",
    "                for part in re.split(r'\\s*[xX]\\s*', raw_text):\n",
    "                    try:\n",
    "                        inch_val = convert_to_inches(part)\n",
    "                        if inch_val > 0:\n",
    "                            bbox = [\n",
    "                                ocr_data['left'][i],\n",
    "                                ocr_data['top'][i],\n",
    "                                ocr_data['left'][i] + ocr_data['width'][i],\n",
    "                                ocr_data['top'][i] + ocr_data['height'][i]\n",
    "                            ]\n",
    "                            dimensions.append({\"raw\": part, \"inches\": inch_val, \"bbox\": bbox})\n",
    "                    except:\n",
    "                        # Ignore parts that fail conversion\n",
    "                        continue\n",
    "\n",
    "    return dimensions, list(set(codes)) # Return unique codes\n",
    "\n",
    "# --- REPLACEMENT FUNCTION for extract_native_codes in Cell 7 ---\n",
    "def extract_native_codes(pdf_path, page_number=0):\n",
    "    \"\"\"\n",
    "    Extracts native, selectable text from a PDF page, finds codes using regex,\n",
    "    and returns both the codes and all the raw text found for debugging.\n",
    "    \"\"\"\n",
    "    codes = []\n",
    "    all_raw_text = []\n",
    "    # Regex for codes like 2030SH or 3040SH (4 digits, 2 uppercase letters)\n",
    "    code_pattern = re.compile(r'^\\d{4}[A-Z]{2}$')\n",
    "    \n",
    "    doc = fitz.open(pdf_path)\n",
    "    page = doc.load_page(page_number)\n",
    "    \n",
    "    # Extract text as a list of blocks\n",
    "    text_blocks = page.get_text(\"blocks\")\n",
    "    \n",
    "    for block in text_blocks:\n",
    "        # The text content is the 5th item in the tuple\n",
    "        text_content = block[4].strip()\n",
    "        if text_content: # Only process non-empty blocks\n",
    "            all_raw_text.append(text_content)\n",
    "            # Check if any word in the block matches the code pattern\n",
    "            for word in text_content.split():\n",
    "                if code_pattern.match(word):\n",
    "                    codes.append(word)\n",
    "                \n",
    "    doc.close()\n",
    "    \n",
    "    # Return unique codes and all the raw text\n",
    "    return list(set(codes)), all_raw_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e96f032",
   "metadata": {},
   "source": [
    "## Step 6: Visualization (Bonus)\n",
    "\n",
    "[cite_start]This bonus function takes the extracted dimensions and draws their bounding boxes and converted inch values directly onto the source image[cite: 16]. This is great for visually verifying the accuracy of the extraction. The final annotated image is then saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e77a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- REPLACEMENT FUNCTION for Cell 9 ---\n",
    "def visualize_results(image, dimensions, output_path):\n",
    "    \"\"\"\n",
    "    Draws bounding boxes and labels for dimensions on the image and saves it.\n",
    "    Labels are placed BELOW the bounding box on a white background for clarity.\n",
    "    \"\"\"\n",
    "    vis_image = image.copy()\n",
    "    \n",
    "    for dim in dimensions:\n",
    "        bbox = dim['bbox']\n",
    "        label = f\"{dim['inches']}\\\"\"\n",
    "        \n",
    "        # Define text properties\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        font_scale = 0.7\n",
    "        font_thickness = 2\n",
    "        text_color = (0, 0, 255) # Red for text\n",
    "        box_color = (0, 0, 255)  # Red for bounding box\n",
    "        bg_color = (255, 255, 255) # White for background\n",
    "\n",
    "        # Get text size to determine background rectangle\n",
    "        (text_width, text_height), baseline = cv2.getTextSize(label, font, font_scale, font_thickness)\n",
    "        \n",
    "        # --- COORDINATE CALCULATION (THE KEY CHANGE) ---\n",
    "        # Position the label's top edge 5 pixels BELOW the bounding box's bottom edge\n",
    "        text_x = bbox[0]\n",
    "        text_y_baseline = bbox[3] + text_height + 5 # 5 is a small padding in pixels\n",
    "\n",
    "        # Calculate coordinates for the background rectangle to sit behind the text\n",
    "        # Top-left corner of the background\n",
    "        bg_rect_start = (text_x, bbox[3] + 5) \n",
    "        # Bottom-right corner of the background\n",
    "        bg_rect_end = (text_x + text_width, bbox[3] + 5 + text_height + baseline)\n",
    "        \n",
    "        # Draw the white background rectangle first\n",
    "        cv2.rectangle(vis_image, bg_rect_start, bg_rect_end, bg_color, -1) # -1 fills the rectangle\n",
    "        \n",
    "        # Draw the red text on top of the white background\n",
    "        cv2.putText(vis_image, label, (text_x, text_y_baseline), \n",
    "                    font, font_scale, text_color, font_thickness, cv2.LINE_AA)\n",
    "        \n",
    "        # Finally, draw the original bounding box rectangle\n",
    "        cv2.rectangle(vis_image, (bbox[0], bbox[1]), (bbox[2], bbox[3]), box_color, 2)\n",
    "    \n",
    "    # Save the visualized image as a temporary file\n",
    "    temp_image_path = os.path.join(OUTPUT_DIR, \"temp_visual.png\")\n",
    "    cv2.imwrite(temp_image_path, vis_image)\n",
    "\n",
    "    # Convert the saved image back to a PDF\n",
    "    with Image.open(temp_image_path) as img:\n",
    "        img.convert('RGB').save(output_path)\n",
    "    \n",
    "    os.remove(temp_image_path) # Clean up temp file\n",
    "    print(f\"Visualization saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10d4a7a",
   "metadata": {},
   "source": [
    "## Main Pipeline Execution\n",
    "\n",
    "This is the final step where we tie everything together. [cite_start]We'll run the full pipeline for each page in the PDF, collect the results, and then save them to the specified JSON and visualized PDF files[cite: 8, 21]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2179af9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page 1...\n",
      "Visualization saved to output\\visualized_floorplan.pdf\n",
      "\n",
      "Extraction complete!\n",
      "JSON output saved to output\\extracted_data.json\n",
      "Found 30 dimensions and 1 codes on page 1.\n"
     ]
    }
   ],
   "source": [
    "# --- REPLACEMENT FUNCTION for main in Cell 11 ---\n",
    "def main():\n",
    "    final_results = {\"pages\": []}\n",
    "    page_num = 0\n",
    "\n",
    "    print(f\"Processing page {page_num + 1}...\")\n",
    "    \n",
    "    # --- Single OCR Pass for ALL data ---\n",
    "    page_image = pdf_page_to_image(INPUT_PDF_PATH, page_number=page_num)\n",
    "    ocr_data = extract_text_with_bboxes(page_image)\n",
    "    \n",
    "    # Process the OCR data to get both dimensions and codes\n",
    "    dimensions, codes = find_and_process_patterns(ocr_data)\n",
    "    \n",
    "    # --- Combine Results ---\n",
    "    page_data = {\n",
    "        \"page\": page_num + 1,\n",
    "        \"dimensions\": dimensions,\n",
    "        \"codes\": codes\n",
    "    }\n",
    "    final_results[\"pages\"].append(page_data)\n",
    "\n",
    "    # Bonus: Visualize the dimension results\n",
    "    if dimensions:\n",
    "         visualize_results(page_image, dimensions, OUTPUT_VISUAL_PATH)\n",
    "\n",
    "    # Save the final JSON output\n",
    "    with open(OUTPUT_JSON_PATH, 'w') as f:\n",
    "        json.dump(final_results, f, indent=4)\n",
    "        \n",
    "    print(f\"\\nExtraction complete!\")\n",
    "    print(f\"JSON output saved to {OUTPUT_JSON_PATH}\")\n",
    "    print(f\"Found {len(dimensions)} dimensions and {len(codes)} codes on page {page_num + 1}.\")\n",
    "\n",
    "# Run the pipeline\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
